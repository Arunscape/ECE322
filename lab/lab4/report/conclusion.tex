In this lab, we were introduced to the black box testing strategy of creating
cause-effect graphs and decision tables to help come up with test cases.
While it would not be fair to say that one testing strategy
is universally better than the other, since it would be better to match
each problem at hand to the appropriate testing strategy, compared to other
testing methods previously learned like dirty testing, error guessing, EPC, and
weak n x 1 strategy, this method seems to demand the most amount of thought and
effort for creating the test cases.
From a subjective standpoint, making cause effect graphs and deriving test
cases from them is an okay testing technique, but not one of my favourites.
While in terms of number of test cases, it is efficient in that it generates
very few test cases while still having generally good coverage, the effort
required to generate the test cases does not seem like it is worth it for most
applications. Additionally, it seems to not cover some scenarios, like in
Task 1 with the CarInsurance program, where invalid inputs were not tested.
There are some scenarios, however, where the testing technique seems
appropriate to use. For example, in Task 2 with the BoilerShutdown application,
it was impossible to enter an invalid input, and we were strictly concerned
with the inputs (causes), and their effects. By creating a simplified
cause effect graph, we created few, but effective test cases. Overall, making
cause-effect graphs and decision tables definitely has its place in black box
testing. Like with any other testing technique, there are scenarios where it
shines, and other cases where another testing technique would work better.


